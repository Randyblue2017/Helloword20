Undo Commit push to remote Repository and rewrite commit

Wednesday, February 23, 2022
9:37 AM

Run:

$git reset --soft HEAD~1					(HEAD~1 = Number of commit you wanna go back. Let say for the last two commits use:   HEAD~2

How to Resolve Branch Conflicts

Wednesday, March 23, 2022
11:45 AM

Resolving Branch Conflict 

Watch YouTube video:

https://www.youtube.com/watch?v=29xipesE8y4


Step to resolve:
	• I’d pull down his changes and make sure not to overwrite them since they’re granting access to eng resources for new developers
	• While on your “Local branch” run:

$git pull origin main		

(This will pull the conflict changes into you local, go into that file and make your change. Just remove the conflict lines and leave your changes and the other dev changes, and save. )


$git add .

$ git commit -m "Resolve conflicts"

$git push 


Do you know how to use git blame or do you have the GitLens extension installed in VS Code? They’ll show you who made a change

I installed GitLens extension already

(with the GitLens extension, if you click on a line in a file, it’ll tell you who added it and when. It’ll add three buttons to the top of each window that let you go back and forth between revisions if you want to see what the file looked like during different commits)


****N/B When resolving conflicts in $kubernetes/clusters/eng-us-east-2.v3/ambassador-main/auth/config/stratis-eng-htpasswd , $kubernetes/clusters/eng-us-east-2.v3/eng-tools/stratis-eng-htpasswd.yaml or $kubernetes/clusters/eng-us-east-2.v3/eng-tools/verdaccio/config-map.yaml you Shouldn’t regenerate configmap, apply configmap before pushing to remote. Just add, commit and push you changes to remote.

<<<<<<< HEAD
  htpasswd: |
=======
  htpasswd: |-
>>>>>>> 9164e8a5cb9ab3893a65fe0d9e6617b6ca000f8c



Undo Commit push to remote Repository and rewrite commit
Wednesday, February 23, 2022
9:37 AM
Run:
 
$git reset --soft HEAD					(HEAD~1 = Number of commit you wanna go back. Let say for the last two commits use:   HEAD~2







# kubectl create secret generic alertmanager-main --from-file=alertmanager.yaml=alertmanager-main.config.yaml
global:
  resolve_timeout: 60m
  slack_api_url: https://hooks.slack.com/services/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
  # smtp_smarthost: smpt.sendgrid.net:465
# smtp_from: "Alertmanager <alertmanager@stratisiot.com>"
# smtp_auth_username: apikey
# smtp_auth_password: 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


route:
  group_by:
  - alertname
  - prometheus
  - namespace
  group_interval: 1m
  group_wait: 1m
  receiver: devops_slack
  repeat_interval: 3h
  routes:
  - match:
      alertname: Watchdog
    receiver: Watchdog
  - match_re:
      namespace: ^(iot-dev|iot-sandbox|notifications-dev|notifications-sandbox|redis-dev|redis-sandbox|vault-dev|vault-sandbox)$
    receiver: iot_slack
    continue: true
  - match_re:
      namespace: ^(none)$
    receiver: iot_slack_critical
    continue: true
    # uncomment this subroute once PD service created
    # routes:
    #   - match:
    #       severity: critical
    #     receiver: iot-pagerduty
    #     continue: true
  # add these in once notification channels for bucloud/acctmgmt are in place
  - match_re:
      namespace: ^(sustain-dev|sustain-sandbox)$
    receiver: sustain_slack
    continue: true
  - match_re:
      namespace: ^(none)$
    receiver: sustain_slack_critical
    continue: true
    # uncomment this subroute once PD service created
    # routes:
    #   - match:
    #       severity: critical
    #     receiver: iot-pagerduty
    #     continue: true
  # add these in once notification channels for bucloud/acctmgmt are in place
  - match_re:
      namespace: ^(bucloud-dev|bucloud-sandbox)$
    receiver: access_slack
    continue: true
  - match_re:
      namespace: ^(none)$
    receiver: access_slack_critical
    continue: true
    # uncomment this subroute once PD service created
    # routes:
    #   - match:
    #       severity: critical
    #     receiver: access_pagerduty
    #     continue: true
  - match_re:
      namespace: ^(acctmgmt-dev|acctmgmt-sandbox|api-dev|api-sandbox)$
    receiver: acctmgmt_slack
    continue: true
  - match_re:
      namespace: ^(none)$
    receiver: acctmgmt_slack_critical
    continue: true
    # uncomment this subroute once PD service created
    # routes:
    #   - match:
    #       severity: critical
    #     receiver: acctmgmt_pagerduty
    #     continue: true
  - match_re:
      namespace: ^(lora)$
    receiver: lora_slack
    continue: true
  - match_re:
      namespace: ^(none)$
    receiver: lora_slack_critical
    continue: true
    # uncomment this subroute once PD service created
    # routes:
    #   - match:
    #       severity: critical
    #     receiver: acctmgmt_pagerduty
    #     continue: true
  - match:
      severity: warning
    receiver: devops_slack
    continue: true
  - match:
      severity: critical
    receiver: devops_slack_critical
    continue: true
  - match:
      severity: critical
    receiver: devops_pagerduty
inhibit_rules:
- equal:
  - alertname
  source_match:
    severity: critical
  target_match_re:
    severity: warning|info


receivers:
- name: devops_slack
  slack_configs:
  - channel: '#eng-cluster-alerts'
    api_url: https://hooks.slack.com/services/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
    title_link: https://alertmanager.eng.stratisiot.com
    title: '{{ template "slack.default.title" . }}'
    text: |-
      {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        *Description:* {{ .Annotations.message }} - {{ .Annotations.description }}
        *Runbook:* {{ .Annotations.runbook_url }}
        *Details:*
        {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
        {{ end }}
      {{ end }} 
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    pretext: '{{ .CommonAnnotations.summary }}'
- name: devops_slack_critical
  slack_configs:
  - channel: '#eng-cluster-alerts'
    api_url: https://hooks.slack.com/services/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
    title_link: https://alertmanager.eng.stratisiot.com
    title: '{{ template "slack.default.title" . }}'
    text: |-
      {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        *Description:* {{ .Annotations.message }} - {{ .Annotations.description }}
        *Runbook:* {{ .Annotations.runbook_url }}
        *Details:*
        {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
        {{ end }}
      {{ end }} 
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    pretext: '{{ .CommonAnnotations.summary }}'
- name: devops_pagerduty
  pagerduty_configs:
  - service_key: cd40e027ad404fffbfcdac0d60c62864
    client_url: https://alertmanager.eng.stratisiot.com
    description: "eng cluster: {{ range .Alerts }}{{ .Annotations.prometheus }}{{ .Annotations.message }}\n{{ .Annotations.description }}\n{{ .Annotations.runbook_url }}\n{{ end }}"
    links:
    - href: https://alertmanager.eng.stratisiot.com
    - text: Alertmanager
- name: iot_slack
  slack_configs:
  - channel: '#iot-alerts'
    api_url: https://hooks.slack.com/services/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
    title_link: https://alertmanager.eng.stratisiot.com
    title: '{{ template "slack.default.title" . }}'
    text: |-
      {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        *Description:* {{ .Annotations.message }} - {{ .Annotations.description }}
        *Runbook:* {{ .Annotations.runbook_url }}
        *Details:*
        {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
        {{ end }}
      {{ end }} 
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    pretext: '{{ .CommonAnnotations.summary }}'
- name: iot_slack_critical
  slack_configs:
  - channel: '#iot-alerts'
    api_url: https://hooks.slack.com/services/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
    title_link: https://alertmanager.eng.stratisiot.com
    title: '{{ template "slack.default.title" . }}'
    text: |-
      {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        *Description:* {{ .Annotations.message }} - {{ .Annotations.description }}
        *Runbook:* {{ .Annotations.runbook_url }}
        *Details:*
        {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
        {{ end }}
      {{ end }} 
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    pretext: '{{ .CommonAnnotations.summary }}'
# - name: iot_pagerduty
#   pagerduty_configs:
#   - service_key: not configured
#     client_url: https://alertmanager.eng.stratisiot.com
#     description: "eng cluster: {{ range .Alerts }}{{ .Annotations.prometheus }}{{ .Annotations.message }}\n{{ .Annotations.description }}\n{{ .Annotations.runbook_url }}\n{{ end }}"
#     links:
#     - href: https://alertmanager.eng.stratisiot.com
#     - text: Alertmanager
- name: sustain_slack
  slack_configs:
  - channel: '"#sustain-alerts"'
    api_url: https://hooks.slack.com/services/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
    title_link: https://alertmanager.eng.stratisiot.com
    title: '{{ template "slack.default.title" . }}'
    text: |-
      {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        *Description:* {{ .Annotations.message }} - {{ .Annotations.description }}
        *Runbook:* {{ .Annotations.runbook_url }}
        *Details:*
        {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
        {{ end }}
      {{ end }} 
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    pretext: '{{ .CommonAnnotations.summary }}'
- name: sustain_slack_critical
  slack_configs:
  - channel: '"#sustain-alerts"'
    api_url: https://hooks.slack.com/services/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
    title_link: https://alertmanager.eng.stratisiot.com
    title: '{{ template "slack.default.title" . }}'
    text: |-
      {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        *Description:* {{ .Annotations.message }} - {{ .Annotations.description }}
        *Runbook:* {{ .Annotations.runbook_url }}
        *Details:*
        {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
        {{ end }}
      {{ end }} 
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    pretext: '{{ .CommonAnnotations.summary }}'
# - name: sustain_pagerduty
#   pagerduty_configs:
#   - service_key: not configured
#     client_url: https://alertmanager.eng.stratisiot.com
#     description: "eng cluster: {{ range .Alerts }}{{ .Annotations.prometheus }}{{ .Annotations.message }}\n{{ .Annotations.description }}\n{{ .Annotations.runbook_url }}\n{{ end }}"
#     links:
#     - href: https://alertmanager.eng.stratisiot.com
#     - text: Alertmanager
- name: access_slack
  slack_configs:
  - channel: '#access-alerts'
    api_url: https://hooks.slack.com/services/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
    title_link: https://alertmanager.eng.stratisiot.com
    title: '{{ template "slack.default.title" . }}'
    text: |-
      {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        *Description:* {{ .Annotations.message }} - {{ .Annotations.description }}
        *Runbook:* {{ .Annotations.runbook_url }}
        *Details:*
        {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
        {{ end }}
      {{ end }} 
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    pretext: '{{ .CommonAnnotations.summary }}'
- name: access_slack_critical
  slack_configs:
  - channel: '#access-alerts'
    api_url: https://hooks.slack.com/services/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
    title_link: https://alertmanager.eng.stratisiot.com
    title: '{{ template "slack.default.title" . }}'
    text: |-
      {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        *Description:* {{ .Annotations.message }} - {{ .Annotations.description }}
        *Runbook:* {{ .Annotations.runbook_url }}
        *Details:*
        {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
        {{ end }}
      {{ end }} 
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    pretext: '{{ .CommonAnnotations.summary }}'
# - name: access_pagerduty
#   pagerduty_configs:
#   - service_key: not configured
#     client_url: https://alertmanager.eng.stratisiot.com
#     description: "eng cluster: {{ range .Alerts }}{{ .Annotations.prometheus }}{{ .Annotations.message }}\n{{ .Annotations.description }}\n{{ .Annotations.runbook_url }}\n{{ end }}"
#     links:
#     - href: https://alertmanager.eng.stratisiot.com
#     - text: Alertmanager
- name: acctmgmt_slack
  slack_configs:
  - channel: '#account-mgmt-alerts'
    api_url: https://hooks.slack.com/services/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
    title_link: https://alertmanager.eng.stratisiot.com
    title: '{{ template "slack.default.title" . }}'
    text: |-
      {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        *Description:* {{ .Annotations.message }} - {{ .Annotations.description }}
        *Runbook:* {{ .Annotations.runbook_url }}
        *Details:*
        {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
        {{ end }}
      {{ end }} 
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    pretext: '{{ .CommonAnnotations.summary }}'
- name: acctmgmt_slack_critical
  slack_configs:
  - channel: '#account-mgmt-alerts'
    api_url: https://hooks.slack.com/services/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
    title_link: https://alertmanager.eng.stratisiot.com
    title: '{{ template "slack.default.title" . }}'
    text: |-
      {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        *Description:* {{ .Annotations.message }} - {{ .Annotations.description }}
        *Runbook:* {{ .Annotations.runbook_url }}
        *Details:*
        {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
        {{ end }}
      {{ end }} 
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    pretext: '{{ .CommonAnnotations.summary }}'
# - name: accountmgmt_pagerduty
#   pagerduty_configs:
#   - service_key: not configured
#     client_url: https://alertmanager.eng.stratisiot.com

#    description: "eng cluster: {{ range .Alerts }}{{ .Annotations.prometheus }}{{ .Annotations.message }}\n{{ .Annotations.description }}\n{{ .Annotations.runbook_url }}\n{{ end }}"
#     links:
#     - href: https://alertmanager.eng.stratisiot.com
#     - text: Alertmanager
- name: lora_slack
  slack_configs:
  - channel: '#lora-alerts'
    api_url: https://hooks.slack.com/services/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
    title_link: https://alertmanager.eng.stratisiot.com
    title: '{{ template "slack.default.title" . }}'
    text: |-
      {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        *Description:* {{ .Annotations.message }} - {{ .Annotations.description }}
        *Runbook:* {{ .Annotations.runbook_url }}
        *Details:*
        {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
        {{ end }}
      {{ end }} 
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    pretext: '{{ .CommonAnnotations.summary }}'
- name: lora_slack_critical
  slack_configs:
  - channel: '#lora-alerts'
    api_url: https://hooks.slack.com/services/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
    title_link: https://alertmanager.eng.stratisiot.com
    title: '{{ template "slack.default.title" . }}'
    text: |-
      {{ range .Alerts }}
        *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        *Description:* {{ .Annotations.message }} - {{ .Annotations.description }}
        *Runbook:* {{ .Annotations.runbook_url }}
        *Details:*
        {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
        {{ end }}
      {{ end }} 
    color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
    pretext: '{{ .CommonAnnotations.summary }}'
# - name: accountmgmt_pagerduty
#   pagerduty_configs:
#   - service_key: not configured
#     client_url: https://alertmanager.eng.stratisiot.com

#    description: "eng cluster: {{ range .Alerts }}{{ .Annotations.prometheus }}{{ .Annotations.message }}\n{{ .Annotations.description }}\n{{ .Annotations.runbook_url }}\n{{ end }}"
#     links:
#     - href: https://alertmanager.eng.stratisiot.com
#     - text: Alertmanager
- name: Watchdog
  # email_configs:
  # - to: "d599ab2448@nosnch.in"



Git Commits
Spliting a Single Commit into two/Multiple commits

Resource: https://www.youtube.com/watch?v=e26Zx9K3cdQ
https://cbea.ms/git-commit/

For this example, I want to split the work into two separate commits, though they were change on the same branch at the same time but I mistakenly push using one commit

- Rese to HEAD spare commits, which is the initial commit

$git reset HEAD~		(Now the changes from the last commits is unstated)

$git status 

$git diff		(Now, we can go ahead and create new commits)

$dit add -p 	(I am going to Stage only the code related to “Setup Dorma-Cora VM” )
Than select s, y, e

- Now, remove the plus sign + from the beginning of the commit you want to stage
- Example: I want to stage only the code related to “Setup Dorma-Cora VM”
- 
- Now, commit it the stage commit, which is “Setup Dorma-Cora VM”: 
- $git diff —staged
- $git commit -m “Setup Dorma-Cora VM”
- $git log —online

Now, make the 2nd commit let says: 

$git diff
$git add .
$git commit -m “Change Three Dorma VMs volume”
$git log —online

What we’re doing is called “Changing History” Only do this on “Branch” you only work on, on on branch the entire team work on

https://git-scm.com/book/en/v2/Customizing-Git-Git-Configuration

Charles url:

https://cbea.ms/git-commit/

https://cbea.ms/git-commit/#separate




Our new Github Commands:

git stash; # stores your working changes
git pull origin main --rebase # pulls most recent changes
git checkout -b lizrbac # makes a new branch
git stash pop # restores your working changes
git add <files you worked on>
git add -u 		(This will only add the currently tracked file and add it to the staging area and if you deleted any file it will remove the deleted file from the staging area as well and ignore all the untracked files.) 
git commit -m “Commit message”		(“Edited answer detail section” 
git push origin
that last one will have a GitHub link in the log output - go to that link and hit the “Create pull request” button

git branch -m NewBranchName	(To rename a Git branch locally that’s already checkout using the terminal)
git branch -m BranchNameYouWannaSwitchTo NewBranchName	(To rename a Git branch locally that’s not checkout using the terminal)
git branch -d NameOfBranch	(To delete a local branch in Git using the terminal, you’re going to run the git branch command and pass in the -d flag. Next, you will pass in the name of the branch you wish to delete)

$ git checkout <name-of-branch-you-want-to-switch-to>	(Switch To another branch on your local branch)
Example
git checkout andresrbac	(Switch branch from current to the branch name andresrbac)



mike  1:30 PM
#devs turning into Mike's GitHub tips

if you want to avoid that --set-upstream message when pushing a new local branch to the remote:
* can set git config --global push.default current once and then do git push as usual
* can just always push with git push -u origin HEAD


*** to link a GitHub commit to an Azure Board task, just write:
AB#{azure board task/ticket id} in the commit message
Curly braces are not literal, so it would look like AB#10933 in practice

Method 1

Adding “AB#10933” to the commit message body on git will create a link in Azure task 10933 automagically

Example: git commit -m “AB#10848 configure unfinished vms”	
Same as: 	$git commit -m “FOUND-10465 configure unfinished vms”			(DD)

Method 2 (Chandler)

By creating a new git branch and reference the azure ticket number 
Example: 
$git checkout -b AB#13814-jevan-rbac

Method 3

By attaching the azure ticket number in you PR commit message 
- After pushing your changes in the repo, add the azure ticket number in the commit message before creating pull request. Example 


stratis-ubnt-us-east



Deleting a remote Branch

$ git push <name-of-remote-repository> --delete <branch-name>	

Deleting a remote branch works a bit differently than deleting a branch locally in Git.
If you run the git branch -d command associated with a remote branch, Git will tell you the branch is not found. You actually won’t be using the git branch command to delete a remote branch. Instead, you will be using the git push command.
Next, you will need to tell Git which remote repository you want to work with, followed by the --delete flag, followed by the branch name.
git branch -r		(to get a list of the remote branches in your Git repository.)

How do you find a list of your remote branches in Git?
If you don’t have the visual benefit of the GitKraken Git client which displays your remote branches, you will need to run git branch -r to get a list of the remote branches in your Git repository.

Want to make working with remote branches in Git easier? Download the GitKraken Git GUI for free.





When you’re working with the branches in your Git repository, it’s common for the need to arise to switch over to another branch. You might need to perform work on another branch, or assist on a code review for a teammate.
The switch action is also referred to as “checkout” in Git. In order to switch to another Git branch using the terminal, you’re going to use the git checkout command.

Checkout Remote Branch in Git

Similar to how you switch between local branches in Git, you’re going to checkout the remote branch in order to switch to the new branch.

if any of yall use git tree, you can see the tree for a specific branch by adding -- <branch_name>.  super helpful for the new github flow

e.g. git tree -- main




**NB

In case you forget to create a feature branch before making you change, do this:

just stash it, make a new branch, stash pop

git stash; 
git checkout -b lizrbac
git stash pop
git add  <files you worked on>
git status 
git commit -m “Commit message”
git push --set-upstream origin branchName	(git push --set-upstream origin andresrbac)

How t switch to another branch on your local machine 
git branch
ls -al 
ls -al .git/
cat .git/HEAD
cat .git/ORIG_HEAD	(To see content of the file)	(You will see the file content a commit ID) which is the same as you type:
git log -n 1	(same as: cat .git/ORIG_HEAD) -n 1 = which is the less commit on this current branch (The commit ID is identical)

git branch randy 	(Will also create a new branch called randy)



How to Rollback deployments or old config in Kubernetes 


apply the old config - you can do a git stash to restore it to its previous state. You should always know how to rollback before you start

To rollback run:

$git stash     (This will restore it to previous state and save you changes on local branch)

$k apply -f stratis-api.secret.yaml	()




Redis Failover 
Deploy operator-managed Redis failovers in test and prod namespaces	(Namespaces on the prob Cluster)

Config.yaml = is the configuration for filling out the templates and the original templates are in the Kubernetes Template folder, there are four of them.

The big thing to know when you’re doing it somewhere else is to specify the environment with the prometheus_metrics_name: example (prometheus_metrics_name: dev) This prometheus_metrics_name is in the dev on the eng- cluster and what I am working on is in the Prod cluster

On the eng Cluster there is only one Redis and it share 3/2 environment but on the Prod Cluster there’s going to be two Redis, it’s gonna be completely separate 

Deploy operator-managed Redis failovers in test and prod namespaces	(Namespaces on the prob Cluster)

So we gonna have a Redis-Test and Redis-Prob on the Prob Cluster. Those Namespaces already exist we’re just adding stuff to them. This simply means we’re just standing up another Redis failover in those namespaces.

** Redis Sentinel Note here
So we’re switching over to the Redis Sentinel model more or less where applications connects directly to the Sentinel.
Sentinel are more like a tool that applications connects to Redis and also each sentinel has a replica that it’s in charge of. So sentinel one for example will be constantly checking did the master fails or no and if it fails the sentinel will make the next replica of master as the main master and if that one fails it going to make the next one the master and if the last one fails they gonna try the main/first master again (This is an example of 3 sentinels, a master and 2 replicas of the master). There is only one master that is used at a time so it means that you will always have an insurance policy in case one of you Redis get’s unavailable, it gives you that full tolerance level. 

There is already a Redis cluster in the Redis-prod and Redis-test namespaces, we want to replace them with the Redis Sentinel replica mode. And operator are little wire with Kubernetes, they’re more less something that manages Kubernetes resources for you, they take a lot of complexity out of running really complex things. We have one for kfaka that handle setting up zeekepper , setting up kfaka, making them talk to each other. Is like having a junior system administrator, there’s a lot of different ways to handle them but what we’re trying to do is have a Redis operator namespace that the operator itself lives in and the Operator is going to manage the resources in Redis-test and Redis-prod, that’s one way to do it. Or you can make separate operators, one in Redis-test and one in Redis-prod if you don’t want to deal with the operator namespace but you’re going to set the operator Namespace to whatever you want it to be with this operator Namespace variable (operator namespace: Redis-operator)

So Charles have the Operator in the Redis-operator Namespace and he have the Redis sentinel replica set in the Redis-dev namespace and he have them setup in the same file. So up in the file is the Redis operator Namespace and further down in the same file under Redis sentinel name is the Redis namespace. Unfortunately, the way he have it setup for now they all are in the same file.

Probably I will do them separate for the prod and the test, and that might make sense having completely separate operators. I can have a single one if I want to save resources, I mean since it is prod it will make sense having completely separate Operators. Anyone of the option is fine as long I can explain my reasoning if someone ask me. When doing it for prod and test Namespace on prod you will want to use more or less the exact same settings and if it looks like cpu and memory are an issues on prod which we won’t know for a while, you can raise those limits but other than that you can just use the settings with couple of changes for the Namespaces

$cd Projects2/ops 	-$cd bin		$./k8sh		$cd ..	$cd Kubernetes 	$cd Cluster 	$cd eng-		$cd redis-operator
Copy same settings in the config.yaml

On prod cluster change operator Namespace to Redis-test and Redis-prod
Change:

For prod
For the Operator Namespace , make it same as whatever you’re using for the redis_and_sentinel_name:  (ex: edis-prod-operator)

prometheus_metrics_name: prod

redis_and_sentinel_name: redis-prod

redis_namespace: redis-prod

 sentinel_replicas: 3

 redis_replicas: 3

For Test

prometheus_metrics_name: test

redis_and_sentinel_name: redis-test

redis_namespace: redis-test

 sentinel_replicas: 3

 redis_replicas: 3


** There’s only one Redis on the eng Cluster which Sandbox and Dev used them it doesn’t distinguish, sandbox doesn’t used that much 

Go to the Gen folder, $cd gen 	$ls 
0-redis-operator-roles.yam		1-redis-operator-service.yaml	2-redis-operator-replicaset.yaml	3-redis.yaml
The major thing to know is that these kinda have to apply in order and you’re going to apply 0, 1 & 2 first, 0, 1 & 2 have to be in ready state before you can apply 3, so you might need to wait a minute or two
The gen folder will need to be created on the prod cluster in the test and prod namespaces and in order to do that you will need to copy the Makefile from the Redis-dev on the eng-us-east cluster to test and prod namespaces 
Steps:
- When in the Redis-operator folder (in this case it will be the “red-test and Redis-prod Namespace) run $make      (This will automatically create the gen folder. But make sure to activate your virtual env/venv) the script is in the make file. So in short the script will creates c	3-redis.yaml  and you’ve to apply it in Kubernetes (kubectl apply -f)


CMD+Shift+N		(Opens another Vscode window)

$cd Projects2/ops 	-$cd bin		$./k8sh		$cd ..	$cd Kubernetes 	$cd Cluster	$cd prod-us-east	

There’s already a Redis-test and Redis-prod folder that I can work in, the namespace and the .k8ns are fine those are both right. I just needs to add the config.yaml and the makefile, I can copy and paste the config.yaml and modify according to environment and copy and paste the Makefile, leave as it is and the gen folder will be created when I run the command $make (I have to activate venv)
Try applying the first 3 from gen ($cd Projects2/ops 	-$cd bin		$./k8sh		$cd ..	$cd Kubernetes 	$cd Cluster) just to see if it start up or they have errors, you can do that on your own no problem I don’t need to talk to him to do that if I am doing that on test

$kubectl apply -f		(Make sure to be in the right namespace) 
Example: 
$kubectl apply -f 0-redis-operator-roles.yam 	(Apply the rest like this)
$kubectl apply -f 1-redis-operator-service.yaml
$kubectl apply -f 2-redis-operator-replicaset.yaml
Verify if the first 3 are deployed/running before applying the last one 	(3-redis.yaml)
To verify:
$kubectl get pods    (There should be x redis pods (they'll have an rfr- in their name) and y sentinel pods (they'll have an rfs- in their 					     name) and a redis-operator pod

$kubectl apply -f 3-redis.yaml


The rest of the other pods has 0,1 and 2 at the end of the label/name 
These are the redis pods - it's a stateful set so they always keep the same name

'''rfr-redis-test-0         1/1   Running  0     24m
rfr-redis-test-1         1/1   Running  0     24m
rfr-redis-test-2         1/1   Running  0     24m'''


so what about the last three pods?
Those are the sentinel pods

There should be x redis pods (they'll have an rfr- in their name) and y sentinel pods (they'll have an rfs- in their name) and a redis-operator pod:


'''rfs-redis-test-5b7984b6f7-pjvsv  1/1   Running  0     24m
rfs-redis-test-5b7984b6f7-qp7mr  1/1   Running  0     24m
rfs-redis-test-5b7984b6f7-t7lj8  1/1   Running  0     24m'''





Should I leave these two fields as, it is for the Redis-test and Redis-prob namespaces? operator_service_account: redis-operator and operator_image: quay.io/spotahome/redis-operator (edited) 
￼
carles  
yes, image = the base docker image, needs to stay the same



please use “`” and “`” around fields so they look like code, makes it easier for others to read

and yeah, use that service account name unless you’ve got a good reason not too




Commit for Redis-test
$git commit -m "Add config.yaml Makefile and deploy redis and sentinel pods to redis-test namespace"

Commit for redis-prod
git commit -m "Add config.yaml Makefile and redis-cluster to redis-prod namespace but redis and sentinel pods not deploy yet"




Kubernetes Rbac File Runbook
Created by randolph.nyepanh
Last updated: Jan 28, 20224 min read6 people viewed6 people viewed
What is Kubernetes rbac file or how does it work?

Rbac means Role base Access Control

We defined a Role and that role exist within a Namespace and each developer can not do anything unless they've been tied to a role in that Namespace or they have a higher level of permission.

You can read more on that: Using RBAC Authorization  

The main Rbac File (rbac.yaml) 

The main rbac defines ClusterRoleBinding. ClusterRoleBinding doesn't have namespaces, the prefix Cluster means they works across the entire cluster. So the ClusterRoleBinding is all of the cluster admin-user and that is all of the SRE team members, if a new SRE team member join they'll need to be added to this ClusterRoleBinding in order to have admin permission. This is different from team specific namespace. This step is a prerequisite for Kubernetes dashboard access and for kubectl and k8sh commands.

Click the link to read more  Using RBAC Authorization 

 

1- Adding Engineers to their team Rbac File

    Developers need  a wide set of permissions to do deployments in a namespace 

     Giving Devs full access

    Adding a Developer under  


roleRef: name: edit 
Means they have pretty much full access permission.     

They log into Pods remotely, create new Deployments, create new Services, scale up/down resources    

      etc. This doesn’t give permissions to custom resources 

2- How to add a Engineer to a namespace and give full access permission

Let say we want to add a new dev engineer name Justice and give full access to the iot-sandbox namespace 

Go to the iot-sandbox namespace and vi/vim into the rbac.yaml file
3- Giving Support Engineers limited permissions: 

pods-exec 

Not everybody that works in a namespace need to make deployments in that namespace. Some users                  don’t need to have permissions to make changes to services because they’re not developer for that team and services. But in some instances engineers need to get in to make a data fix or interact with the database somehow, that is why we may want to give them limited access and this is where pod-exec comes into place.

 How to add a Support Engineer to a namespace and give pod-exec permission 

Add a support engineer name blue to the bucloud-sandbox namespace and give pod-exec Permission

See previous example

Under the pod-exec role copy the entire block for any of the user.

Preview unavailable
Save and apply your changes. 

 

3- Sometimes an engineer may switch teams or leave the company. When this happens, we need to either remove that engineer from their former team namespace and add to the new team namespace. 

If engineer is no longer employ with the company, we need to remove them from all of the namespaces they were added to.

Follow the same steps, go to that namespace, and remove engineer from all roles, save and apply your changes.  

Instructions for validating

For devs run:
3- Sometimes an engineer may switch teams or leave the company. When this happens, we need to either remove that engineer from their former team namespace and add to the new team namespace. 

If engineer is no longer employ with the company, we need to remove them from all of the namespaces they were added to.

Follow the same steps, go to that namespace, and remove engineer from all roles, save and apply your changes.  

Instructions for validating

For devs run:


kubectl auth can-i create pods --as=<their email> -n <namespace>
should return yes. 

For support engineer run:


kubectl auth can-i get pods --as=<their email> -n <namespace>



Port Forwarding

Intended Audience
Network Operation Engineers Team 

Support Engineering Team

Access Development Team 

DevSecOps/SRE Team

Announcement of Change
See article here: Unannounced - Change in How to Access Dormakaba and Windows VMs 

Terms and Concepts
Shared folder in LastPass called AWS Remote Desktop Users

AWS Management Console

VMs (Windows Instances) 

Remote Desktop Protocol 

Port Forwarding 

 

Prerequisites
Access to the AWS Management Console 

Points of contact

RealPage

See: Service Request for a Security Group

Set up the AWS CLI (Remote Desktop Users Only)

AWS SSO With RealPage Active Directory 

Access to the AWS Remote Desktop Users Shared Folder in LastPass

Points of contact:

DevSecOps (@Chandler Reid @Andrew Snyder @Charles Hufnagel @Kelly Campbell (Unlicensed) @randolph.nyepanh @jasmine.adams)

#dev_ops channel on Slack

@dev_ops_oncall for urgent assistanc

Optional: Access to the ops-tools repo in gerrit

https://gerrit.bulogics.com/admin/repos/ops-tools 

 

SOP
 

Using AWS Console (PowerShell only, no Remote Desktop) 
Navigate to the AWS Console 

Navigate to EC2 


Make sure your Region is set to US West (Oregon) us-west-2. This is the AWS region where Dormakaba and Salto live. 


 

Search for your Instance in the Filter Instances search bar 


 

Mark the checkbox next to the instance, then select the Connect button


 

Select Session Manager, and click Connect


 

You will be presented with a PowerShell Admin terminal on that instance. 


 

 

Using Port Forwarding (Remote Desktop) 
Port forwarding is a technique that redirects traffic destined from Port A and sends it to Port B. In this case, Port A is on your local computer, Port B will be on the remote VM. 

This takes a little bit more setup, but is a great way to connect to the VMs. You don’t have to be on the VPNs, or wait around for Chandler to add your JumpCloud user to the AWS Instance. 

 

Here’s a link to way more information than you need to get this working.

 

Port forwarding requires the following: 

Session Manager Plugin: https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-working-with-install-plugin.html#install-plugin-windows

InstanceId of the VM you’re working with

 

 

Get the InstanceId of your target VM
You have several options.

The easiest way is to get to the EC2 Management Console (shown in the Using the AWS Console section above) and search for your site. The InstanceId will be in the column to the right. 


Make sure to grab the entire instance ID, starting with i-. 

 

The next easiest way is to clone the ops-tools repo, then run bin/get-aws-ec2-instance-ids


❯ ./bin/aws-get-ec2-instance-ids
Dormakaba - Devops Dev, i-00543bb3434767fdd
unifi-west.netmgmt, i-0ccaf947ef70ea2b0
Salto - Access Dev, i-0efb28cfa3189070e
Dormakaba - District at Chandler, i-022eca2034740f591
Dormakaba - Elan Madison Yards, i-0c6fb94c509483b54
Dormakaba - Union Chapel Hill, i-016456d331112eb2c
 

Easily the worst way to get your instances is to use the AWS CLI. Seriously, don’t do it to yourself. 


aws ec2 describe-instances --query 'Reservations[].Instances[].[InstanceId,Tags[?Key==`Name`].Value]' --output text
We explicitly do not want to maintain a separate list of VMs and their Instance IDs. This list would have to be updated frequently, and AWS already provides one :slight_smile: 

 

Set up Port Forwarding
Got your InstanceId? Got your Plugin set up? Great, let’s close this out. 

Mac/Linux: 


aws ssm start-session --target <InstanceId> --document-name AWS-StartPortForwardingSession --parameters '{"portNumber":["3389"],"localPortNumber":["9999"]}'
 

Windows


aws ssm start-session --target "i-04ea27010fc359874" --document-name AWS-StartPortForwardingSession --parameters portNumber=3389,localPortNumber=9999
If you’re ever connecting to multiple VMs at once, change the localPortNumber parameter so that they are both pointing to different ports. You cannot have two applications running on the same port. 

 

 

Setting up your Remote Desktop Connection Manager

You do not have to do this step after setting up the port forwarding. It can be set up at any time. 

Again, you have several options here. You can choose to add a new PC in your Remote Desktop Connection Manager for each VM, or you can have a generic one for each. I’d recommend at least two, in case you ever need to connect to two at once. 

 

Open your Remote Desktop application

Select Add PC
Fill in the following information

PC Name- 127.0.0.1:9999- This is your computer, and the port you specified in the localPortNumber parameter when you started your session. 

User Account - This name is arbitrary, but will be the information found in the LastPass Shared Folder AWS Remote Desktop Users, mentioned in the Prerequisites section at the top of this document. 

Friendly Name- Arbitrary. Name it something easy to find for you if you have multiple PCs set up. 


 

 

 

Press Save. Double Click the connection you just created to connect to it. 

 

Transferring files to a Windows VM
Redirect folders are the safest way to transfer files (install files, upgrade files, etc). Here’s how to set them up.

Disconnect from the remote desktop (if there is a session running). 

Click the folders tab, then the + button, then open the folder locally on your computer.


Connect to the Remote Desktop

Open the File Explorer in Windows. Navigate to Network and then tsclient. In this folder, you’ll find all the files in the redirect folder(s) you added.

Preview unavailable






How to increase Dorma and Salto Volume on AWS Console
Created by randolph.nyepanh
Last updated: Feb 07, 20224 min read4 people viewed4 people viewed
Checkout the amazon documentation for more:  Request modifications to your EBS volumes - Amazon Elastic Compute Cloud 

Step 1: 

The volume on an EC2 instance is where the storage is. Volumes can be resized in place, and that’s safe to do as long as it’s being resized up (instead of down)

 

1- Go to aws console and make sure you are in the us-west-2 region (Oregon)

2- Search for the VM by the name and highlight it by clicking the box next to the VM

3- Scroll down and select the "Storage" tab   


 

4- Click the the Volume ID Example: vol-014cb8b7827b9e02a


 

5- Select the "Action" tab in the upper right corner and select "Modify Volume"


6- Now, enter your desire volume size, and select the modify tab when done. (Leave all other as it is)


7- Refresh the page after few second and you should see the change

Preview unavailable
 

Step 2: 

Once the volume is resized, you need to tell the Operating System that it has more space to work with. This is called Extending the volume. You can do it via the GUI or Powershell, and there’s no downtime associated with it.

 

How to Extend the Volume using Powershell 

 

use links to get more details: Extend a Windows file system after resizing a volume - Amazon Elastic Compute Cloud 

Before extending a file system that contains valuable data, it is a best practice to create a snapshot of the volume that contains it in case you need to roll back your changes. For more information, see Create Amazon EBS snapshots. Create Amazon EBS snapshots - Amazon Elastic Compute Cloud 

 

Extend a Windows file system using PowerShell

1- Log in to your Windows instance using Remote Desktop. To get to the Remote Desktop screen click the connect tab in the upper right.


2- Run PowerShell as an administrator.

Preview unavailable
3- Check the disk size


Get-volume 
You should see the same size of the volume

Preview unavailable
 

4- Run the Get-Partition command. PowerShell returns the corresponding partition number for each partition, the drive letter, offset, size, and type. Note the drive letter of the partition to extend. My drive-letter is: C


Get-Partition
Preview unavailable
 

5- Run the following command to rescan the disk.


"rescan" | diskpart
Preview unavailable
 

6- Run the following command, using the drive letter you noted in # 4 in place of <drive-letter> in my case I am using C. PowerShell returns the minimum and maximum size of the partition allowed, in bytes.


Get-PartitionSupportedSize -DriveLetter <drive-letter>
Preview unavailable
 

7- To extend the partition to a specified amount, run the following command, entering the new size of the volume in place of <size>. You can enter the size in KB, MB, and GB; for example, 50GB. In the example below I want to increase to 75GB

        


   Resize-Partition -DriveLetter <drive-letter> -Size <size> 
This command might throw error, if it does ignore and run the next command in #8

Preview unavailable
 

8- To extend the partition to the maximum available size, run the following command.


Resize-Partition -DriveLetter <drive-letter> -Size $(Get-PartitionSupportedSize -DriveLetter <drive-letter>).SizeMax
 

Preview unavailable
9 


Get-Volume 
To verify change

Preview unavailable
 

 

How to Extend the Volume using the

 

Use Link to follow steps:  Extend a Windows file system using the Disk Management utility


Importing Resources into Terraform




How To: Import resource into terraform

The resources must be declared in the main.tf file before being able to import them. The resource must be defined in the codebase. You must also run terraform init. 

terraform import <terraform_state_name> <resource_identifier>

Importing a Dormakaba Property into Terraform

We track the AWS Instance, Elastic IP, and two AWS Route53 Records. Four terraform resources per property

terraform import module.<opaque_id>.<terraform_resource_name>.<name> <resource_identifier>

For EC2 Instances, use the Instance ID

terraform import module.p-99k4ca.aws_route53_record.p-99k4ca-external p-99k4ca.dk.stratisiot.com

For DNS Records, the pattern must be HOSTED-ZONE-ID_DNS-RECORD_RECORD-TYPE 

terraform import module.p-99k4ca.aws_route53_record.p-99k4ca-external ZG1GGZK0PD2V2_p-99k4ca.dk.stratisiot.com_A

terraform import module.p-99k4ca.aws_route53_record.p-99k4ca-internal ZG1GGZK0PD2V2_solis.dk.stratisiot.com_A

For Elastic IP Addresses, use the Elastic IP Allocation ID

 terraform import module.p-99k4ca.aws_eip.p-99k4ca "eipalloc-0433b9630bd684e08"

 

Errors: 


❯ terraform import module.p-mba1qp.aws_instance.mba1qp "i-0d5e8baa691a872dd"Error: resource address "module.p-mba1qp.aws_instance.p-mba1qp" does not exist in the configuration.

Before importing this resource, please create its configuration in module.p-mba1qp. For example:

resource "aws_instance" "p-mba1qp" {
#(resource arguments)
}
 

After importing a logical batch of resources (the four used to create a VM, for example) run terraform plan. If there are no changes that need to happen to the infrastructure, then you’re done! This will not always be the case. At a minimum, make sure you’re not creating any additional resources, this is not the goal of importing. If you’re creating resources, there is most likely a configuration that will cause a resource to be destroyed and then recreated, which could cause a disruption. If this happens, use terraform plan to identify the changes that must happen in the resources, make a fix either in the configuration file or in the AWS console, and apply the change. 
* You’ll most likely want to fix the configuration file - what’s live in AWS is already live in AWS, and probably isn’t the thing that needs to change

~ subnet_id = "subnet-03020b9fadb252070" -> "subnet-03b8249ab7bc3aa05" # forces replacement

Terraform will tell you which thing that’s changing will force replacement. ^ 

As of Terraform version 0.14.0 - Terraform plan will only tell you one thing that will force replacement until you’re done. If you fix one thing that forces replacement, run terraform plan again to make sure you’ve fixed any disruptive changes. 

Note: Not all changes will be a bad thing. In many cases, you’ll import a resource and the terraform file will have helpful additions that the non-terraform AWS resource did not (additional tags, boosted EBS volume sizes, new security group IDs, etc.) Each imported resource must be judged on a case-by-case basis. If you’re unsure, ask the team! 

Remember, terraform apply creates any changes immediately. make sure you’re cool with whatever is changing before applying. 






HomeBrew
Paste the following code into a macOS Terminal or Linux shell prompt:

/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

To verify that you have installed correctly run:

brew -v
Expected output : Homebrew 3.0.8 (or latest version)

MySQL 5.7
At this time of writing, Homebrew has MySQL version 8 as default, but as we're aiming to get 5.7, we'll need to append @5.7 to the default package key:

brew info mysql@5.7
Expected output : mysql@5.7: stable 5.7.22 (bottled) [keg-only]

If you get the expected output, continue with installation:

brew install mysql@5.7

To verify that you have installed correctly, install brew services:

 brew tap homebrew/services

Load and start the MySQL service : 

brew services start mysql@5.7
Expected output : Successfully started mysql (label: homebrew.mxcl.mysql)

Check of the MySQL service has been loaded : 

brew services list
Expected output : mysql@5.7 started your.username /Users/your.username/path

Force link 5.7 version -

brew link mysql@5.7 --force

Verify the installed MySQL instance : 

mysql -V
Expected output : Ver 14.14 Distrib 5.7.22, for osx10.13 (x86_64)

pip
Python comes preinstalled on most computers, and pip comes preinstalled with Python. However, this is not always the case. Run the following to check what you have installed:

python --version
Expected output : Python 2.7.16 or latest version

pip --version
Expected output : pip 20.3.4 from /Library/path/… (python 2.7) or latest version

 

If you do not have pip,  install:

sudo easy_install pip==20.3.4

Verify again: 

pip --version
Expected output : pip 20.3.4 from /Library/path/… (python 2.7) or latest version

Virtual Env
Install virtualenv via pip:

pip install virtualenv

To give your terminal access to the virtualenv command, run:

sudo /usr/bin/easy_install virtualenv

To verify installation, run the following:

virtualenv --version
Expected output : virtualenv 20.4.3 from /Users/your.user/path/… or latest version

Node via NVM
First install NVM via brew:

brew install nvm

Verify the installed NVM instance : 

nvm -v
Expected output : 0.37.2 or latest version

Next, create a directory for NVM:

mkdir ~/.nvm

Now point NVM to use this new directory (add this to your bash profile and source it):

export NVM_DIR=~/.nvm
source $(brew --prefix nvm)/nvm.sh

Echoing $NVM_DIR should now return your NVM directory:

echo $NVM_DIR
Expected output : /Users/your.username/.nvm

Next, check what Node versions are available to install:

nvm ls-remote

This should return a complete list of Node versions. You should install the latest version. As of the most recent update to this doc, the latest point release of Node is v16.1.0 so I ran:

nvm install 16

Now, to verify Node is installed, run:

node -v
Expected output : v16.1.0 or latest version

NPM
NPM is distributed with Node.js which means that when you downloaded Node.js, you automatically got NPM installed on your computer. To verify, run:

npm -v
Expected output : 6.14.11 or latest version

NOTE: You may need to run npm login for some of our apps to build. This will allow you to create and setup an account on our local NPM module server (you can use a throwaway password).

RabbitMQ
First install RabbitMQ via brew:

brew install rabbitmq

Edit your .rc file (Ex. .bashrc, .zshrc) to include the following exports:


export PATH=$PATH:/usr/local/sbin
Now, restart your terminal. The above export should make the following command available. To verify, run:

rabbitmq-server
Expected output : Starting broker... completed with 6 plugins.

You can ctrl-C once you have verified that RabbitMQ is able to run.

Bazel
Install Bazel with Homebrew:

brew install bazel

Verify Bazel installation with the following:

bazel --version
Expected output : bazel 4.0.0-homebrew or latest version

gRPC
Install gRPC with the following:

brew install grpcurl

Verify gRPC installation with the following:

grpcurl --version
Expected output : grpcurl 1.8.0 or latest version

iBazel
Install iBazel with Homebrew:


brew tap bazelbuild/tap
brew install bazelbuild/tap/ibazel
Verify Bazel installation with the following:

ibazel --version
Expected output : the help menu (including version number)

Docker (via minikube)
Docker can run applications in an isolated environment on your machine called containers. It gives you the flexibility to run multiple containers at once and also ensures everything runs uniformly regardless of which machine you are on. They have a desktop app that you can download to manage these containers.

Step 1: Install Docker, Docker Compose, and a VM driver


brew install docker docker-compose

After installation, you may need to also link docker-compose as a Docker plugin (e.g. you might find Compose is now a Docker plugin. For Docker to find this plugin, symlink it when installing Docker Compose)

mkdir -p ~/.docker/cli-plugins
ln -sfn /usr/local/opt/docker-compose/bin/docker-compose ~/.docker/cli-plugins/docker-compose

You can choose VirtualBox, HyperKit, or another driver if you know what you are doing. Because of this issue relating to how Docker volumes are handled in HyperKit, we recommend VirtualBox over HyperKit.

To install the VirtualBox driver via Homebrew:


brew install --cask virtualbox
VirtualBox will need elevated permissions so follow the prompts as necessary. You will likely need to restart your machine. 

System Preferences -> Security & Privacy -> Allow -> Then allow the software corporation (in this case Oracle)

Step 2: Install minikube

curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64
sudo install minikube-darwin-amd64 /usr/local/bin/minikube

Step 3: Set defaults for minikube to use
NOTE: change these to your liking, this matches the Docker Desktop's settings


minikube config set driver virtualbox  # hyperkit if you installed HyperKit instead
minikube config set cpus 6
minikube config set memory '4g'
minikube config set disk-size '60g'
Step 4: Start Minikube
NOTE: You will need to start this every time you reboot


minikube start && eval $(minikube docker-env)
Optional
Login to do the bulogics docker using your htpasswd


docker login docker.bulogics.com
Troubleshooting
If you previously had installed Docker Desktop you may need to clear your config


echo "{}" > ~/.docker/config.json
kubectl issues
minikube affects your kubectl contexts. If you are on a cluster and you cannot list the expected namespaces for example, you can adjust your context.
To get contexts:


kubectl config get-contexts
(Example output)

CURRENT   NAME                                      CLUSTER                                   AUTHINFO                 NAMESPACE
*         eng-us-east-2.v3.eng.k8s.stratisiot.net   eng-us-east-2.v3.eng.k8s.stratisiot.net   michael@stratisiot.com   
          minikube                                  minikube                                  minikube                 default
	  

To switch contexts when necessary:


 kubectl config use-context <context>
To switch to the eng cluster for example:


 kubectl config use-context eng-us-east-2.v3.eng.k8s.stratisiot.net
localhost refused to connect
Ports in Docker images are not exposed on localhost when running Docker containers with minikube. So if you expect to hit a service at localhost:8000, you can find that service at $(minikube ip):8000.

To find the IP address minikube is running on, run minikube ip in a terminal.

Tips
You will need to run minikube start before using Docker between machine restarts. To avoid doing so, you can write a script that just starts up minikube and configure that script to run at login. However keep in mind this approach will take up resources on your machine even when you are not using Docker or minikube, so you may just want to start minikube manually every time you need it for Docker.

Example script:


#!/bin/zsh

minikube start

You will also need to run eval $(minikube docker-env) in any shell where you are leveraging Docker so Docker knows about minikube.

If you want to have your ~/.zprofile set it up automatically, you can put the following in there:


if minikube status &>> /dev/null
then
    eval $(minikube docker-env)
fi
Training Link
Video Conferencing, Web Conferencing, Webinars, Screen Sharing  Passcode: Pk4#jJ%5

iTerm2
This is an upgraded terminal with additional features for macOS users only. You can follow this link or click the download button below to download directly:

Preview unavailable
Once downloaded, you should use this terminal from now on. Feel free to familiarize yourself with iTerm2’s unique features by clicking this link

Postman
You can follow this link to download or (if you are using OSX) click the download button below to download directly:

Preview unavailable
InVision
InVision is a digital product design app. Access to this must be granted by RealPage. In the Service Request tab in RealPage’s Salesforce, start a new ticket.

Choose End User Support as your Record Type, and Software as the Category.

Preview unavailable
 

There will be a list of checkboxes on the bottom right of your screen for Software Requiring Purchase. Check the InVision box. You’ll need to give a very brief justification of why you want access to this software in the Justification text box. Choose the date that you’ll need access by, then Submit. RealPage should grant you access within a few days.

Java
Open up the RealPage Software Center on your laptop. It looks like this:

Preview unavailable
Search for “JDK.” Click “install” to install OpenJDK.

Preview unavailable
java --version


Windows Port Forwarding

Thursday, March 10, 2022
5:44 PM

aws ssm start-session --target i-048ewi3954e47939 --document-name AWS-StartPortForwardingSession --parameters '{"portNumber":["3389"],"localPortNumber":["9999"]}'
